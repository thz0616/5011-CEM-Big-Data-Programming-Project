Decision Tree


#DECISION TREE CLASSIFIER
import os
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, classification_report
)
import joblib

# =====================
# 1. è¯»å–æ•°æ®
# =====================
df = pd.read_csv("data/ExtractedC.csv", sep=";")
df.columns = df.columns.str.strip()   # å»æ‰å¤šä½™ç©ºæ ¼/tab

assert "Target" in df.columns, "âš  æ²¡æœ‰æ‰¾åˆ° 'Target' åˆ—ï¼Œè¯·æ£€æŸ¥ CSV æ–‡ä»¶"

X = df.drop("Target", axis=1)
y = df["Target"]

# One-hot ç¼–ç  (é€‚åˆåˆ†ç±»å˜é‡)
X = pd.get_dummies(X, drop_first=True)

# æ•°æ®é›†åˆ’åˆ†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# =====================
# 2. Pipeline + GridSearchCV
# =====================
pipe = Pipeline([
    ("scaler", StandardScaler()),  # è™½ç„¶å†³ç­–æ ‘ä¸ä¸€å®šéœ€è¦æ ‡å‡†åŒ–ï¼Œä½†åŠ ä¸Šæ²¡åå¤„
    ("clf", DecisionTreeClassifier(random_state=42))
])

param_grid = {
    "clf__criterion": ["gini", "entropy"],
    "clf__max_depth": [None, 5, 10, 20, 30],
    "clf__min_samples_split": [2, 5, 10],
    "clf__min_samples_leaf": [1, 2, 4],
    "clf__class_weight": [None, "balanced"]
}

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

grid = GridSearchCV(
    pipe,
    param_grid,
    scoring="f1_weighted",
    cv=cv,
    n_jobs=-1,
    verbose=1
)

# è®­ç»ƒ + è°ƒå‚
grid.fit(X_train, y_train)

print("âœ… Best Params:", grid.best_params_)
best_model = grid.best_estimator_

# =====================
# 3. æ¨¡å‹è¯„ä¼°
# =====================
y_pred = best_model.predict(X_test)

# éƒ¨åˆ†ç±»åˆ«çš„æƒ…å†µéœ€è¦ try-except åŒ…è£¹ AUC
try:
    y_prob = best_model.predict_proba(X_test)[:, 1]
    auc = roc_auc_score(y_test, y_prob)
except Exception:
    auc = None

print("\nğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ")
print("Accuracy :", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average="weighted"))
print("Recall   :", recall_score(y_test, y_pred, average="weighted"))
print("F1 Score :", f1_score(y_test, y_pred, average="weighted"))
if auc:
    print("AUC      :", auc)

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# =====================
# 4. ä¿å­˜æœ€ä½³æ¨¡å‹
# =====================
os.makedirs("models", exist_ok=True)
joblib.dump(best_model, "models/best_decisiontree.pkl")
print("\nğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ° models/best_decisiontree.pkl")

# =====================
# 5. ä¿å­˜è¯„ä¼°ç»“æœ
# =====================
results = {
    "accuracy": accuracy_score(y_test, y_pred),
    "precision": precision_score(y_test, y_pred, average="weighted"),
    "recall": recall_score(y_test, y_pred, average="weighted"),
    "f1": f1_score(y_test, y_pred, average="weighted"),
    "auc": auc
}
results_df = pd.DataFrame([results])
results_df.to_csv("data/DecisionTreeResults.csv", sep=";", index=False)
print("ğŸ“„ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ° data/DecisionTreeResults.csv")
